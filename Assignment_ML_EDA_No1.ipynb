{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ce67894-3450-4fb7-9a62-0dae61732bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assignment:Foundation of Machine learning and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "024e3929-15bd-4686-9bda-890ce7247587",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. What is the difference between AI,ML,DL nad data science? Provide  abreif explanation of each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcc81bbc-91f4-4c42-9b69-b8259583e6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans Artificial Intelligence (AI)\n",
    "\n",
    "#AI (Artificial Intelligence) is the broadest concept — it refers to machines or systems that can perform tasks that normally require human intelligence.\n",
    "#Goal: Enable machines to think, reason, and act intelligently.\n",
    "#Examples:Chatbots like me (ChatGPT)\n",
    "#Machine Learning (ML)\n",
    "#ML is a subset of AI that allows machines to learn from data and improve performance without being explicitly programmed.\n",
    "#Goal: Learn patterns from data and make predictions or decisions.\n",
    "#Examples:Spam email detection\n",
    "#Deep Learning (DL)\n",
    "#DL is a subset of Machine Learning that uses artificial neural networks with many layers to model complex data patterns.\n",
    "#Goal: Mimic how the human brain works using neural networks.\n",
    "#Examples:Voice assistants (Siri, Alexa)\n",
    "#Data Science\n",
    "#Data Science is a broader field that involves collecting, cleaning, analyzing, and interpreting data to gain insights and support decision-making.\n",
    "#Goal: Extract useful knowledge from data using statistics, ML, and data visualization.\n",
    "#Examples:\n",
    "#Business performance dashboards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7621ff6b-bdec-4e56-991d-e2cdd1f8a67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. EXPLAIN OVERFITTING AND UNDERFITTING IN ml. How can you detect and prevent them?\n",
    "#Ans:Overfitting happens when a model learns the training data too well — including noise, outliers, and random fluctuations — so it performs very well on training data but poorly on test (unseen) data.\n",
    "#Example:\n",
    "#Imagine a student memorizes answers from a textbook instead of understanding the concepts. They’ll do great on practice questions (training) but fail in the exam (testing).\n",
    "#Signs of Overfitting:\n",
    "#Training accuracy → very high (e.g., 99%)\n",
    "#Test accuracy → much lower (e.g., 70%)\n",
    "#Model is too complex (many parameters, deep trees, large neural nets)\n",
    "#How to Prevent / Reduce Overfitting:\n",
    "\n",
    "#a) Simplify the model – use fewer features or smaller networks\n",
    "#b) Regularization – add penalties (L1, L2) to reduce complexity\n",
    "#c) Cross-validation – test model performance on multiple data splits\n",
    "#d)Early stopping – stop training when validation loss starts to increase\n",
    "#e) Dropout (for neural networks) – randomly ignore some neurons during training\n",
    "#f)Data augmentation – artificially increase training data (e.g., rotate images)\n",
    "\n",
    "#Underfitting happens when a model is too simple to capture the underlying patterns in data.\n",
    "#It performs poorly on both training and test data.\n",
    "#Example:\n",
    "#A student who hasn’t studied enough—can’t even answer the practice questions correctly.\n",
    "#Signs of Underfitting:\n",
    "#Low accuracy on both training and testing datasets\n",
    "#Model fails to capture patterns or relationships\n",
    "#Model is too simple (e.g., linear model for complex nonlinear data)\n",
    "#How to Prevent / Fix Underfitting:\n",
    "#a) Increase model complexity – use deeper models or more features\n",
    "#b) Train longer – allow the model to learn more patterns\n",
    "#c) Reduce regularization – avoid over-penalizing model parameters\n",
    "#d) Feature engineering – add more relevant or derived features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "940bb863-d109-4ba5-8dcb-bff4829319ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age   Salary\n",
      "0  25.0  50000.0\n",
      "1  30.0  60000.0\n"
     ]
    }
   ],
   "source": [
    "#3. How do you handle missing values in a dataset?Explain atleast three methods with examples?\n",
    "#Ans:Listwise Deletion (Remove rows)\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Age': [25, 30, None, 40],\n",
    "    'Salary': [50000, 60000, 55000, None]\n",
    "})\n",
    "\n",
    "# Remove rows with any missing value\n",
    "df_clean = df.dropna()\n",
    "print(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37d4184d-8fef-47a5-924b-f669acb5a8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Age   Salary\n",
      "0  25.000000  50000.0\n",
      "1  30.000000  60000.0\n",
      "2  31.666667  55000.0\n",
      "3  40.000000  55000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajesh.kumar\\AppData\\Local\\Temp\\ipykernel_308\\3771682985.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
      "C:\\Users\\rajesh.kumar\\AppData\\Local\\Temp\\ipykernel_308\\3771682985.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Salary'].fillna(df['Salary'].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# b)Mean / Median / Mode Imputation\n",
    "#Replace missing values with the mean, median, or mode of the column.\n",
    "# Fill missing values with mean\n",
    "df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "\n",
    "# Fill missing values with median\n",
    "df['Salary'].fillna(df['Salary'].median(), inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "170dd3a1-898b-43f6-9953-5e7878d5dbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Gender\n",
      "0    Male\n",
      "1    Male\n",
      "2  Female\n",
      "3    Male\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajesh.kumar\\AppData\\Local\\Temp\\ipykernel_308\\46056482.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Gender'].fillna(df['Gender'].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#Mode Imputation (for categorical data)\n",
    "df = pd.DataFrame({'Gender': ['Male', None, 'Female', 'Male']})\n",
    "df['Gender'].fillna(df['Gender'].mode()[0], inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88f5cc04-f516-4e7a-87af-5eac935432be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age   Salary\n",
      "0  25.0  50000.0\n",
      "1  30.0  60000.0\n",
      "2  35.0  55000.0\n",
      "3  27.5  65000.0\n"
     ]
    }
   ],
   "source": [
    "#Predictive Imputation (Model-Based)\n",
    "#Use an ML model to predict missing values based on other features.\n",
    "#Example:\n",
    "#Use Linear Regression to predict missing “Salary” using “Age”.\n",
    "#Or use K-Nearest Neighbors (KNN) Imputer from sklearn.\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Age': [25, 30, 35, None],\n",
    "    'Salary': [50000, 60000, None, 65000]\n",
    "})\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=2)\n",
    "df_imputed = imputer.fit_transform(df)\n",
    "print(pd.DataFrame(df_imputed, columns=df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6c9228c-ec1c-4c2a-896b-6f2ff2912c80",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m---> 11\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, stratify\u001b[38;5;241m=\u001b[39my, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     12\u001b[0m smote \u001b[38;5;241m=\u001b[39m SMOTE(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     13\u001b[0m X_resampled, y_resampled \u001b[38;5;241m=\u001b[39m smote\u001b[38;5;241m.\u001b[39mfit_resample(X_train, y_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# What is an imbalanced dataset? Describe two technique to handle it?\n",
    "#An imbalanced dataset is one in which the classes (categories) are not represented equally.\n",
    "#In other words, one class (the majority class) has many more samples than the other class (the minority class).\n",
    "#Techniques to Handle Imbalanced Data\n",
    "#(i) Oversampling (Increase minority samples)\n",
    "# Common method: SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "#It creates new synthetic samples by interpolating between existing minority samples.\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "566911c2-f1d8-47d2-affb-48344af9910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.Why is features scaling important in ML? Compare Min-Max scaling and standarardization.\n",
    "#Ans:Feature scaling is one of the most important preprocessing steps in Machine Learning, especially for algorithms that depend on the magnitude of features (like KNN, SVM, Gradient Descent-based models).\n",
    "#Feature scaling means transforming numerical features so that they share a \n",
    "#common scale or range — without distorting differences in their ranges or distributions.\n",
    "#Min–Max Scaling (Normalization)\n",
    "#Formula:X′=Xmax​−Xmin​X−Xmin​​\n",
    "#Range:Transforms data to a fixed range [0, 1] (sometimes [-1, 1]).\n",
    "#Standardization (Z-score Scaling)\n",
    "#Formula: X′=σX−μ​\n",
    "#Where:\n",
    "#μ = mean of feature\n",
    "#σ = standard deviation of feature\n",
    "#Result:\n",
    "#Feature has mean = 0 and standard deviation = 1.\n",
    "#Values can be positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7351f40-c5df-4b15-8a5c-efc2342da008",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6.Compare label Encoding and one hot encoding?\n",
    "#Machine Learning models cannot directly understand text or categorical data — they only work with numerical values.\n",
    "#So, we use encoding techniques to convert categorical values into numbers. Example Red, green, yellow encoded into 0,1,2\n",
    "#Advantages:\n",
    "#Simple and memory-efficient\n",
    "#Works well for ordinal data (where order matters), e.g. Low < Medium < High\n",
    "# Disadvantages:\n",
    "#Implies ordinal relationship even when none exists\n",
    "#(e.g., model may think Red > Blue > Green, which is incorrect)\n",
    "#One-Hot Encoding\n",
    "#One-Hot Encoding converts each category into a new binary column (0 or 1) — only one column is “hot” (1) for each observation.\n",
    "#Color\n",
    "#Color\tRed\tBlue\tGreen\n",
    "#Red\t1\t0\t0\n",
    "#Blue\t0\t1\t0\n",
    "#Green\t0\t0\t1\n",
    "#Advantages:\n",
    "#No ordinal relationship introduced\n",
    "#Suitable for nominal (unordered) categories\n",
    "# Disadvantages:\n",
    "#Increases dimensionality (many new columns if many categories)\n",
    "#Less efficient for high-cardinality features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
